{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Count of Oil and Gas Wells in the US by County\n",
    "\n",
    "## Explanation of Project\n",
    "\n",
    "While working as an intern for an environmental economics organization, one of the projects I was a part of was a rangeland/cropland conservation project throughout several US states (Texas, Wyoming, New Mexico, Oklahoma, Colorado, Kansas, and Nebraska). The level of granularity for the project was at the county level, and we needed a way to differentiate the counties based on their oil and natural gas output.\n",
    "\n",
    "The first way I did this was by finding production amounts by county for oil and natural gas, which were readily available online. After completing this, I was also asked to verify/support this approach by also figuring out the total number of oil and natural gas wells per county.\n",
    "\n",
    "While this projet has already been completed and visualized and completed on the first website below, the data from that website is raw and only labels the wells by Latitude and Longitude, without their corresponding county name. Because of that, my approach to labeling the wells with their county name and aggregating that is layed out below. The total number of wells was 1.7 million, which, as shown below, put a constraint on the realistic methods I could use to assign the correct county names to each latitude/longitude"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Sources\n",
    "\n",
    "I accessed the well data from this website: https://www.fractracker.org/2015/08/1-7-million-wells/\n",
    "It has a listing of all the wells in the United States, excluding offshore, North Carolina, and Texas\n",
    "\n",
    "To get the data for Texas, I went to this site: http://www.rrc.state.tx.us/oil-gas/research-and-statistics/well-information/well-distribution-by-county-well-counts/\n",
    "\n",
    "The well data for Texas was already aggregated by county, so it is not included as part of assigning the county names to the latitudes and longitudes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process to Aggregate the Data\n",
    "\n",
    "It took a little bit of trial and error to find the best way to get the county information from the Lat/Longs\n",
    "\n",
    "I found a python library that could do it with something called Noominatim from open street map, but it had a request limit that was prohibitive for the amount of entries I had. The process of using Noominatim to query the GEOID information is not included in this notebook, but it is esentially the same as querying the US Census website\n",
    "\n",
    "I then found the Census API where you can use a website link with specific Lat and Longs inputted to return a JSON of descriptive data about the location, including county name and GEOID. This method was faster, but still too slow to process the entire dataset.\n",
    "\n",
    "So my next step was to download a dataset of Latitude/Longitude pairs with associated county information from the US Census into a text file. These Lat and Long pairs that had GEOID labels could be used to to train a K-Nearest Neighbors algorithm to predict the remainder of the un-labeled Lat/Longs. I chose K-Nearest Neighbors as opposed to another algorithm because the input feature set was two dimensional, and the problem itself was inherently spatial, so I thought it would be a good fit.\n",
    "\n",
    "\n",
    "*As a note, the part of this project that is not included in this notebook is the final solution I used to get the county names. I used QGIS along with a shapefile which had polygon boundaries of each county, so that a specific Lat/Long point could be place within a certain county. This is important, as the nearest neighbor algorithm could get it wrong if there is not a high enough density of points along the border between two counties, and the closest point is within the incorrect county*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Methodolgy and High-Level Explanation of Notebook\n",
    "\n",
    "While the final method used in QGIS to get the GEOID information from the Lat/Longs was used instead of the K-Nearest Neighbors algorithm, the notebook below shows my process. After first setting aside a testing set to test the KNN algorithm on, and seeing where it failed, I was interested to see how many new points it would take (by querying the census API) to get to a certain acceptable level of accuracy with the KNN algorithm. I created some functions to do this (as well as using the census API to generate testing data), and after a couple of iterations, realized it was prohibitively slow.\n",
    "\n",
    "*With that, the file I save below called 'GEOIDS_Progress.csv' is just a checkpoint so that I can shutdown the notebook and keep the extra labeled Lat/Longs that I had already queried from the census API and not have to start over with redefining the original versions of each of the dataframes.*\n",
    "\n",
    "*The file: 'wells_original.csv' is just an aggregation of the 3 raw data files taken from the website, trimmed down to just the states I was looking at for this project.*\n",
    "\n",
    "*The file: 'Original_Census_Data.csv' is the original text file with Lat/Longs and GEOID information taken from the census website, trimmed down to just the states in this project.*\n",
    "\n",
    "*The file: 'Data_for_GIS.csv' is the well data trimmmed down to just the Lat/Longs, the state code, and the state abbreviation (with duplicates removed), to be fed into QGIS along with the county shapefile.*\n",
    "\n",
    "*The file: 'predicted.csv' has the predicted county ID's from the KNN model for each Lat/Long combination.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Step: Importing Libraries and Cleaning the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#######========> Import libraries needed for this notebook\n",
    "\n",
    "import pandas as pd #Data manipulation library\n",
    "import numpy as np #Numerical python\n",
    "import requests #Libary to get the information in JSON format from the census API\n",
    "import datetime #Library I used to time how long a chunk of code takes to run (just for curiosity)\n",
    "from sklearn.metrics import accuracy_score #Metric to test accuracy of KNN\n",
    "from sklearn.neighbors import KNeighborsClassifier #KNN algorithm\n",
    "\n",
    "#######========> End importing of libraries needed for this notebook\n",
    "\n",
    "#######========> Define the columns of each file to be used, and data types\n",
    "\n",
    "#The census link to access information about a Lat,Long pair\n",
    "site = 'http://data.fcc.gov/api/block/find?format=json'\n",
    "\n",
    "cols = ['State','Well_Name','Operator','Type','Status',\n",
    "        'Spud Date','Longitude','Latitude','API']\n",
    "\n",
    "types = {'State': str, 'Well_Name': str, 'Operator': str, \n",
    "         'Type': str, 'Status': str, 'Spud Date': str, \n",
    "         'Longitude': str, 'Latitude': str, 'API': str}\n",
    "\n",
    "#######========> End column type definition\n",
    "\n",
    "#######========> Read the three files containing well data into dataframes\n",
    "\n",
    "#Define file path for the well data\n",
    "path = '~/Desktop/Earth Economics/AngelaWork/OilandGas/'\n",
    "\n",
    "data1 = pd.read_csv(path + 'Well_Data/wells1.csv', \n",
    "                    encoding=\"ISO-8859-1\", \n",
    "                    usecols = cols, \n",
    "                    dtype = types)\n",
    "data2 = pd.read_csv(path + 'Well_Data/wells2.csv', \n",
    "                    encoding=\"ISO-8859-1\", \n",
    "                    usecols = cols, \n",
    "                    dtype = types)\n",
    "data3 = pd.read_csv(path + 'Well_Data/wells3.csv', \n",
    "                    encoding=\"ISO-8859-1\", \n",
    "                    usecols = cols, \n",
    "                    dtype = types)\n",
    "\n",
    "#######========> End dataframe creation from original csv files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Now, concatenate the three dataframes into one, and save this file as a csv**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>State</th>\n",
       "      <th>Well_Name</th>\n",
       "      <th>Operator</th>\n",
       "      <th>Type</th>\n",
       "      <th>Status</th>\n",
       "      <th>Spud Date</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>API</th>\n",
       "      <th>LatLong</th>\n",
       "      <th>State_Code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>154331</th>\n",
       "      <td>WY</td>\n",
       "      <td>JOHN F JESSEN 1</td>\n",
       "      <td>Z &amp; S CONSTRUCTION CO INC</td>\n",
       "      <td>Oil Well</td>\n",
       "      <td>Producing Oil Well</td>\n",
       "      <td>19850727</td>\n",
       "      <td>-104.05490</td>\n",
       "      <td>41.30750</td>\n",
       "      <td>2120376</td>\n",
       "      <td>41.30750,-104.05490</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154332</th>\n",
       "      <td>WY</td>\n",
       "      <td>JESSEN 24-26</td>\n",
       "      <td>BEAR OIL AND GAS INC</td>\n",
       "      <td>Oil Well</td>\n",
       "      <td>Subsequent Report of Abandonment</td>\n",
       "      <td>20120917</td>\n",
       "      <td>-104.05519</td>\n",
       "      <td>41.31780</td>\n",
       "      <td>2120969</td>\n",
       "      <td>41.31780,-104.05519</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154333</th>\n",
       "      <td>WY</td>\n",
       "      <td>MALM 42-34</td>\n",
       "      <td>RANCH OIL COMPANY</td>\n",
       "      <td>Oil Well</td>\n",
       "      <td>Producing Oil Well</td>\n",
       "      <td>20100814</td>\n",
       "      <td>-104.05672</td>\n",
       "      <td>41.48507</td>\n",
       "      <td>2120659</td>\n",
       "      <td>41.48507,-104.05672</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154334</th>\n",
       "      <td>WY</td>\n",
       "      <td>AFTON GREEN 1</td>\n",
       "      <td>HARRISON SAM G</td>\n",
       "      <td>Oil Well</td>\n",
       "      <td>Subsequent Report of Abandonment</td>\n",
       "      <td>19641223</td>\n",
       "      <td>-104.05738</td>\n",
       "      <td>41.62074</td>\n",
       "      <td>1505009</td>\n",
       "      <td>41.62074,-104.05738</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154335</th>\n",
       "      <td>WY</td>\n",
       "      <td>CHARLES 5-10 1</td>\n",
       "      <td>DARRAH JOHN JAY JR</td>\n",
       "      <td>Oil Well</td>\n",
       "      <td>Subsequent Report of Abandonment</td>\n",
       "      <td>19961207</td>\n",
       "      <td>-104.06029</td>\n",
       "      <td>43.02864</td>\n",
       "      <td>2720972</td>\n",
       "      <td>43.02864,-104.06029</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       State        Well_Name                   Operator      Type  \\\n",
       "154331    WY  JOHN F JESSEN 1  Z & S CONSTRUCTION CO INC  Oil Well   \n",
       "154332    WY     JESSEN 24-26       BEAR OIL AND GAS INC  Oil Well   \n",
       "154333    WY       MALM 42-34          RANCH OIL COMPANY  Oil Well   \n",
       "154334    WY    AFTON GREEN 1             HARRISON SAM G  Oil Well   \n",
       "154335    WY   CHARLES 5-10 1         DARRAH JOHN JAY JR  Oil Well   \n",
       "\n",
       "                                  Status Spud Date   Longitude  Latitude  \\\n",
       "154331                Producing Oil Well  19850727  -104.05490  41.30750   \n",
       "154332  Subsequent Report of Abandonment  20120917  -104.05519  41.31780   \n",
       "154333                Producing Oil Well  20100814  -104.05672  41.48507   \n",
       "154334  Subsequent Report of Abandonment  19641223  -104.05738  41.62074   \n",
       "154335  Subsequent Report of Abandonment  19961207  -104.06029  43.02864   \n",
       "\n",
       "            API              LatLong State_Code  \n",
       "154331  2120376  41.30750,-104.05490         56  \n",
       "154332  2120969  41.31780,-104.05519         56  \n",
       "154333  2120659  41.48507,-104.05672         56  \n",
       "154334  1505009  41.62074,-104.05738         56  \n",
       "154335  2720972  43.02864,-104.06029         56  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#######========> Define list of states in the project, and the mapping for their codes\n",
    "\n",
    "#List the states that I am interested in to trim down the file\n",
    "states = ['WY','NM','OK','CO','KS','NE']\n",
    "\n",
    "#Dictionary mapping the states to their codes\n",
    "state_dict = {'CO': '08', 'KS': '20', 'NE': '31',\n",
    "              'NM': '35', 'OK': '40', 'WY': '56'}\n",
    "\n",
    "#######========> End state abbreviation/code definition\n",
    "\n",
    "#######========> Concatenate dataframes, trim down to states in list, and add relevant columns\n",
    "\n",
    "#Concatenate the three original files into one.\n",
    "wells_og = pd.concat([data1, data2, data3])\n",
    "\n",
    "#Trim down the file to only include the states relevant to the project\n",
    "wells_og = wells_og[wells_og.State.isin(states)]\n",
    "\n",
    "#Combined column to get a shorter list of unique Lat/Longs\n",
    "wells_og['LatLong'] = wells_og.Latitude + ',' + wells_og.Longitude\n",
    "\n",
    "#Column of the state codes for each state\n",
    "wells_og['State_Code'] = wells_og.State.map(state_dict)\n",
    "\n",
    "#######========> End dataframe concatenation and preparation\n",
    "\n",
    "#######========> Save wells data to csv, and display the prepared dataframe\n",
    "\n",
    "#Save the original wells data file\n",
    "wells_og.to_csv(path + 'Well_Data/wells_original.csv')\n",
    "\n",
    "#Display the first five rows of the data\n",
    "wells_og.head()\n",
    "\n",
    "#######========> End file saving and display"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The file 'US.txt' is the downloaded file from the US Census website, it is a tab separated file, so can be read into pandas with the standard read_csv function, just with the separator changed to '\\t' instead of ','**\n",
    "\n",
    "**The code below loads the file in, and does similar trimming and column addition to the wells dataframes above**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>State</th>\n",
       "      <th>State_Code</th>\n",
       "      <th>County</th>\n",
       "      <th>GEOID</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LatLong</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>38.27252,-99.93346</th>\n",
       "      <td>38.27252</td>\n",
       "      <td>-99.93346</td>\n",
       "      <td>KS</td>\n",
       "      <td>20</td>\n",
       "      <td>135</td>\n",
       "      <td>20135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38.20001,-97.45587</th>\n",
       "      <td>38.20001</td>\n",
       "      <td>-97.45587</td>\n",
       "      <td>KS</td>\n",
       "      <td>20</td>\n",
       "      <td>113</td>\n",
       "      <td>20113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39.19027,-96.5625</th>\n",
       "      <td>39.19027</td>\n",
       "      <td>-96.5625</td>\n",
       "      <td>KS</td>\n",
       "      <td>20</td>\n",
       "      <td>161</td>\n",
       "      <td>20161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37.15252,-98.5498</th>\n",
       "      <td>37.15252</td>\n",
       "      <td>-98.5498</td>\n",
       "      <td>KS</td>\n",
       "      <td>20</td>\n",
       "      <td>007</td>\n",
       "      <td>20007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38.47823,-98.42495</th>\n",
       "      <td>38.47823</td>\n",
       "      <td>-98.42495</td>\n",
       "      <td>KS</td>\n",
       "      <td>20</td>\n",
       "      <td>159</td>\n",
       "      <td>20159</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Latitude  Longitude State State_Code County  GEOID\n",
       "LatLong                                                               \n",
       "38.27252,-99.93346  38.27252  -99.93346    KS         20    135  20135\n",
       "38.20001,-97.45587  38.20001  -97.45587    KS         20    113  20113\n",
       "39.19027,-96.5625   39.19027   -96.5625    KS         20    161  20161\n",
       "37.15252,-98.5498   37.15252   -98.5498    KS         20    007  20007\n",
       "38.47823,-98.42495  38.47823  -98.42495    KS         20    159  20159"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#######========> Read US Census datafile into pandas dataframe, trim, and clean data\n",
    "\n",
    "#Use tab separator, and define columns to use and their data types\n",
    "file = pd.read_csv(path + 'Well_Data/US.txt', sep = '\\t', usecols = [4,5,10,11], \n",
    "                   header = None, dtype = {4: str, 5:str, 10:str, 11:str})\n",
    "\n",
    "#Name the columms appropriately\n",
    "file.columns = ['Latitude','Longitude','State','County']\n",
    "\n",
    "#There were some Lats/Longs that didn't have a county so I dropped those\n",
    "file = file[file.County.notnull()] \n",
    "\n",
    "#Limit the file to just the states related to this project\n",
    "file = file[file.State.isin(states)]\n",
    "\n",
    "#Create a column to match to the wells dataframe\n",
    "file['LatLong'] = file.Latitude + ',' + file.Longitude\n",
    "\n",
    "#Map the states to their state codes\n",
    "file['State_Code'] = file.State.map(state_dict)\n",
    "\n",
    "#Create a GEOID by concatenating the state codes with the county #'s\n",
    "file['GEOID'] = file['State_Code'] + file.County\n",
    "\n",
    "#Get rid of any duplicate Lat/Long combinations to trim the dataset\n",
    "file = file.drop_duplicates('LatLong')\n",
    "\n",
    "#Set index as the latitudes and longitudes concatenated together\n",
    "file = file.set_index('LatLong')\n",
    "\n",
    "#Reorder the census columns\n",
    "file = file[['Latitude','Longitude','State','State_Code','County','GEOID']]\n",
    "\n",
    "#######========> End dataframe creation, trimming, and cleaning\n",
    "\n",
    "#######========> Save trimmed data to csv file and display the dataframe\n",
    "\n",
    "#Save the original Census data to csv\n",
    "file.to_csv(path + 'Well_Data/Original_Census_Data.csv')\n",
    "\n",
    "#Display the first five rows of the Census data\n",
    "file.head()\n",
    "\n",
    "#######========> End file saving and display"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**My next step is to trim down the original wells data set into a version that will be used in QGIS. This involves leaving just the columns needed to get the county information. These are: Lat/Longs, States, State_Codes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>State</th>\n",
       "      <th>State_Code</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LatLong</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>41.30750,-104.05490</th>\n",
       "      <td>41.30750</td>\n",
       "      <td>-104.05490</td>\n",
       "      <td>WY</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41.31780,-104.05519</th>\n",
       "      <td>41.31780</td>\n",
       "      <td>-104.05519</td>\n",
       "      <td>WY</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41.48507,-104.05672</th>\n",
       "      <td>41.48507</td>\n",
       "      <td>-104.05672</td>\n",
       "      <td>WY</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41.62074,-104.05738</th>\n",
       "      <td>41.62074</td>\n",
       "      <td>-104.05738</td>\n",
       "      <td>WY</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43.02864,-104.06029</th>\n",
       "      <td>43.02864</td>\n",
       "      <td>-104.06029</td>\n",
       "      <td>WY</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Latitude   Longitude State State_Code\n",
       "LatLong                                                   \n",
       "41.30750,-104.05490  41.30750  -104.05490    WY         56\n",
       "41.31780,-104.05519  41.31780  -104.05519    WY         56\n",
       "41.48507,-104.05672  41.48507  -104.05672    WY         56\n",
       "41.62074,-104.05738  41.62074  -104.05738    WY         56\n",
       "43.02864,-104.06029  43.02864  -104.06029    WY         56"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#######========> Create new wells dataframe which gets rid of columns not needed in QGIS\n",
    "\n",
    "#Drop duplicates and create a new wells frame to be manipulated\n",
    "wells = wells_og.drop_duplicates('LatLong')\n",
    "\n",
    "#Set the index to the concatenated Lat/Longs\n",
    "wells = wells.set_index('LatLong')\n",
    "\n",
    "#Define the columns to be dropped\n",
    "drop_cols = ['Operator','Well_Name','Type','Status','Spud Date','API']\n",
    "\n",
    "#Get rid of unecessary columns\n",
    "wells = wells.drop(drop_cols, axis = 1)\n",
    "\n",
    "#Reorder the columns\n",
    "wells = wells[['Latitude','Longitude','State','State_Code']]\n",
    "\n",
    "#######========> End QGIS ready dataframe creation\n",
    "\n",
    "#######========> Save the dataframe to a csv file and display it\n",
    "\n",
    "#Create a file to input into the GIS software\n",
    "wells.to_csv(path + 'Predicted_Counties_For_LatLong/Data_for_GIS.csv')\n",
    "\n",
    "#Display first five rows of trimmed wells data\n",
    "wells.head()\n",
    "\n",
    "#######========> End file saving and display"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Now I want to combine the files in order to more easily use the nearest neighbors and generate new data when needed. So the join used is a full outer join, so that all unique Lat/Long combinations are included, and if there is any exact matches in the Census dataset, I won't need to re-predict or search those.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>State</th>\n",
       "      <th>State_Code</th>\n",
       "      <th>County</th>\n",
       "      <th>GEOID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>38.27252</td>\n",
       "      <td>-99.93346</td>\n",
       "      <td>KS</td>\n",
       "      <td>20</td>\n",
       "      <td>135</td>\n",
       "      <td>20135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>38.20001</td>\n",
       "      <td>-97.45587</td>\n",
       "      <td>KS</td>\n",
       "      <td>20</td>\n",
       "      <td>113</td>\n",
       "      <td>20113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>39.19027</td>\n",
       "      <td>-96.5625</td>\n",
       "      <td>KS</td>\n",
       "      <td>20</td>\n",
       "      <td>161</td>\n",
       "      <td>20161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>37.15252</td>\n",
       "      <td>-98.5498</td>\n",
       "      <td>KS</td>\n",
       "      <td>20</td>\n",
       "      <td>007</td>\n",
       "      <td>20007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>38.47823</td>\n",
       "      <td>-98.42495</td>\n",
       "      <td>KS</td>\n",
       "      <td>20</td>\n",
       "      <td>159</td>\n",
       "      <td>20159</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Latitude  Longitude State State_Code County  GEOID\n",
       "0  38.27252  -99.93346    KS         20    135  20135\n",
       "1  38.20001  -97.45587    KS         20    113  20113\n",
       "2  39.19027   -96.5625    KS         20    161  20161\n",
       "3  37.15252   -98.5498    KS         20    007  20007\n",
       "4  38.47823  -98.42495    KS         20    159  20159"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Merge the census data and the trimmed wells data with an outer join\n",
    "combined = file.merge(wells, how = 'outer')\n",
    "\n",
    "#Display first five rows of the combined data set. Many GEOIDS are null\n",
    "combined.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checkpoint for Current Progress from Census API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**So what I did, just out of curiosity's sake, is build a function to generate new random samples to see how much the addition of a few hundred to a few thousand labeled Lat/Longs would improve the algorithm (which it definitely did).**\n",
    "\n",
    "**This cell below is a checkpoint, as when I wanted to close this notebook, or it timed out or I had to force quit it for any reason, I wouldn't lose all of the new GEOID's I had gathered. I saved a file called 'GEOID_Progess.csv' so that I could just start from this cell when I restarted the notebook**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>State</th>\n",
       "      <th>State_Code</th>\n",
       "      <th>County</th>\n",
       "      <th>GEOID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>38.27252</td>\n",
       "      <td>-99.93346</td>\n",
       "      <td>KS</td>\n",
       "      <td>20</td>\n",
       "      <td>135</td>\n",
       "      <td>20135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>38.20001</td>\n",
       "      <td>-97.45587</td>\n",
       "      <td>KS</td>\n",
       "      <td>20</td>\n",
       "      <td>113</td>\n",
       "      <td>20113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>39.19027</td>\n",
       "      <td>-96.5625</td>\n",
       "      <td>KS</td>\n",
       "      <td>20</td>\n",
       "      <td>161</td>\n",
       "      <td>20161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>37.15252</td>\n",
       "      <td>-98.5498</td>\n",
       "      <td>KS</td>\n",
       "      <td>20</td>\n",
       "      <td>007</td>\n",
       "      <td>20007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>38.47823</td>\n",
       "      <td>-98.42495</td>\n",
       "      <td>KS</td>\n",
       "      <td>20</td>\n",
       "      <td>159</td>\n",
       "      <td>20159</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Latitude  Longitude State State_Code County  GEOID\n",
       "0  38.27252  -99.93346    KS         20    135  20135\n",
       "1  38.20001  -97.45587    KS         20    113  20113\n",
       "2  39.19027   -96.5625    KS         20    161  20161\n",
       "3  37.15252   -98.5498    KS         20    007  20007\n",
       "4  38.47823  -98.42495    KS         20    159  20159"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#######========> Import libraries needed for this notebook and define Census API link\n",
    "\n",
    "import pandas as pd #Data manipulation library\n",
    "import numpy as np #Numerical python\n",
    "import requests #Libary to get the information in JSON format from the census API\n",
    "import datetime #Library I used to time how long a chunk of code takes to run (just for curiosity)\n",
    "from sklearn.metrics import accuracy_score #Metric to test accuracy of KNN\n",
    "from sklearn.neighbors import KNeighborsClassifier #KNN algorithm\n",
    "\n",
    "#The census link to access information about a Lat,Long pair\n",
    "site = 'http://data.fcc.gov/api/block/find?format=json'\n",
    "\n",
    "#######========> End importing of libraries needed for this notebook\n",
    "\n",
    "#######========> Bring in the progress file, define column data types, and display\n",
    "\n",
    "#Define all the columns as having data type of string\n",
    "dtypes = {'Latitude' : str, 'Longitude' : str, 'State' : str, \n",
    "          'State_Code' : str, 'County' : str, 'GEOID' : str}\n",
    "\n",
    "#Read the progress file into pandas dataframe\n",
    "combined = pd.read_csv(path + 'Predicted_Counties_For_LatLong/GEOIDS_Progress.csv',\n",
    "                       dtype = dtypes)\n",
    "\n",
    "#Display first five rows of the dataframe\n",
    "combined.head()\n",
    "\n",
    "#######========> End display and reading of csv file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Several Functions for Sample Generation and Model Training/Prediction\n",
    "\n",
    "**The gen_new algorithm just takes a list of the states and the number of samples I want to generate, so I can choose the subset of states and increase or decrease the amount of new data I want to generate (takes a long time).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#######========> Define function to generate new correct Lat/Longs paired with GEOID's for training\n",
    "\n",
    "def gen_new(states, samples):\n",
    "    \n",
    "    #iterate over the states given to the function\n",
    "    for state in states:\n",
    "        \n",
    "        #Define the sample of the dataframe for the indexes to be pulled from\n",
    "        df_trim = combined[(combined.GEOID.isnull())&(combined.State == state)]\n",
    "        \n",
    "        #Define if statement to ensure more samples are asked for than exist\n",
    "        if df_trim.shape[0] < samples:\n",
    "            df = df_trim.sample(df_trim.shape[0])\n",
    "        else:\n",
    "            df = df_trim.sample(samples)\n",
    "        \n",
    "        #Iterate over the indexes in the sampled dataframe\n",
    "        for index in df.index:\n",
    "            \n",
    "            #Definte the latitude\n",
    "            Lat = combined.loc[index, 'Latitude']\n",
    "            \n",
    "            #Define the longitude\n",
    "            Long = combined.loc[index, 'Longitude']\n",
    "            \n",
    "            #Get the county information from the Census API\n",
    "            geoid = requests.get(site + '&latitude=' + Lat + \n",
    "                                 '&longitude=' + Long + \n",
    "                                 '&showall=true').json()['County']['FIPS']\n",
    "            \n",
    "            #Assign the geoid give by the census to that row\n",
    "            combined.loc[index, 'GEOID'] = geoid\n",
    "            \n",
    "        #Get confirmation that it is runnning properly\n",
    "        print(state + ' is finished...')\n",
    "    return None\n",
    "\n",
    "#######========> End function for creating new training examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**So in order to accurately see how well the nearest neighbors algorithm was performing, I needed to create an out of sample testing set. So this takes a set and a number of samples, and returns a dataframe that can be used to accurately test the accuracy of the prediction.**\n",
    "\n",
    "**I could have split the data into training and testing samples and done cross validation to have a larger testing set for determining the accuracy score which wouldn't have taken as long as developing new samples, but I just leaned more towards having the entire data for training. Also, since I was able to generate truly out of sample data by not adding these generated samples to the data, I thought that would be a plus too.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#######========> Define function to generate an out of sample testing set\n",
    "\n",
    "def test_sample(state, sample_num):\n",
    "    \n",
    "    #Create empty lists to store the values\n",
    "    Lats, Longs, geoids = [], [], []\n",
    "    \n",
    "    #Define the trimmed dataframe that test sample will be pulled from\n",
    "    df_trim = combined[(combined.GEOID.isnull())&(combined.State == state)]\n",
    "    \n",
    "    #Define if statement to ensure more samples are asked for than exist\n",
    "    if df_trim.shape[0] < sample_num:\n",
    "        df = df_trim.sample(df_trim.shape[0])\n",
    "    else:\n",
    "        df = df_trim.sample(sample_num)\n",
    "    \n",
    "    #Loop over the indexes in the trimmed dataframe\n",
    "    for index in df.index:\n",
    "        \n",
    "        #Store the latitudes and Longitudes at the index\n",
    "        Lat = combined.loc[index, 'Latitude']\n",
    "        Long = combined.loc[index, 'Longitude']\n",
    "        \n",
    "        #Take the Lat/Longs for this iteration and get the county info\n",
    "        geoid = requests.get(site+'&latitude='+Lat+'&longitude=' \n",
    "                            +Long+'&showall=true').json()['County']['FIPS']\n",
    "        \n",
    "        #Append the Lat/Long/Geoid to each of their respective lists\n",
    "        Lats.append(Lat)\n",
    "        Longs.append(Long)\n",
    "        geoids.append(geoid)\n",
    "        \n",
    "    #Create a numpy array of all three lists (Lat, Long, Geoids)\n",
    "    LatLong = np.array([Lats, Longs, geoids])\n",
    "    \n",
    "    #Turn this into a dataframe which gets returned from the function\n",
    "    test_frame = pd.DataFrame(LatLong.T,columns=['Latitude','Longitude','GEOID'])\n",
    "    \n",
    "    return test_frame\n",
    "\n",
    "#######========> End function to define out of sample testing set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**This function (train_algo) takes the list of states, the number of trials I want to run, and the number of samples per trial and returns the accuracy scores for each state (100% being the best).**\n",
    "\n",
    "**My reasoning for doing the algorithm at the state level was that this would eliminate any confusion when two states border each other and there isn't enough data for the algorithm to determine which state it is in. This doesn't solve the problem of data being right on the county border, but it makes it a little more accurate at least.**\n",
    "\n",
    "**When testing the algorithm, I tested many different values for n_neighbors (how many nearest points the algorithm looks at), and setting it to 1 always produced the best accuracy that I found.**\n",
    "\n",
    "**I did try other algorithms as well such as Random Forest and Linear Regression, but nearest neighbors worked better**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#######========> Define function to train the data on the KNN model\n",
    "\n",
    "def train_algo(states, numtrials, sample_num):\n",
    "    \n",
    "    #Define the X and Y columns to be used for training the model\n",
    "    xcols = ['Latitude','Longitude']\n",
    "    ycols = ['GEOID']\n",
    "    \n",
    "    #Create an empty list to store the accuracy values for each state\n",
    "    accuracy = []\n",
    "    \n",
    "    #Define the KNN model with N_Neighnors = 1\n",
    "    model = KNeighborsClassifier(n_neighbors = 1)\n",
    "    \n",
    "    #Iterate over each of the states passed to the function\n",
    "    for state in states:\n",
    "        \n",
    "        #Declare a current value variable\n",
    "        current = 0\n",
    "        \n",
    "        #Define the dataframe for the given state\n",
    "        df = combined[(combined.GEOID.notnull())&(combined.State == state)]\n",
    "        \n",
    "        #Iterate over the number of trials passed to the function\n",
    "        for trial in range(numtrials):\n",
    "            \n",
    "            #Define the x_train and y_train sets based on the x and y columns\n",
    "            x_train = df[xcols]\n",
    "            y_train = df[ycols]\n",
    "            \n",
    "            #Call the test_sample function to create a new dataframe of testing data\n",
    "            test_frame = test_sample(state, sample_num)\n",
    "            \n",
    "            #Define the testing set based on the function that gets new testing samples\n",
    "            x_test, y_test = test_frame[xcols], test_frame[ycols].values.ravel()\n",
    "            \n",
    "            #Fit the model to the x_train and y_train dataframes\n",
    "            model.fit(x_train,y_train.values.ravel())\n",
    "            \n",
    "            #Use the trained model to make a prediction on the testing set\n",
    "            y_pred = model.predict(x_test)\n",
    "            \n",
    "            #Calcualte the accuracy score of y_compared to y_predicted\n",
    "            current += accuracy_score(y_test, y_pred)\n",
    "        \n",
    "        #Append the average of the accuracy scores of the num_trials to the accuracy list\n",
    "        accuracy.append(current/numtrials)\n",
    "        \n",
    "        #Use this print statement to give user feedback that code is functioning properly\n",
    "        print(state + ' is finished...')\n",
    "        \n",
    "    #Return the list with the average accuracy scores calculated\n",
    "    return accuracy\n",
    "\n",
    "#######========> End function creation to train the KNN model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**This chunk of code below just generates new data by calling the Census API for each state based on what 'samples' is set to**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WY is finished...\n",
      "NM is finished...\n",
      "OK is finished...\n",
      "CO is finished...\n",
      "KS is finished...\n",
      "NE is finished...\n",
      "0:00:36\n"
     ]
    }
   ],
   "source": [
    "#######========> Implement code to generate new data points, and calculate time elapsed\n",
    "\n",
    "#Define starting time\n",
    "a = datetime.datetime.now().replace(microsecond = 0)\n",
    "\n",
    "#Define set of states to be passed to gen_new function\n",
    "states = ['WY','NM','OK','CO','KS','NE']\n",
    "\n",
    "#Define number of new data points to be queried from the Census API\n",
    "samples = 10\n",
    "\n",
    "#Call the function with the above parameters, it returns none, just overwrites existing dataframe\n",
    "gen_new(states, samples)\n",
    "\n",
    "#Define ending time and print the difference between the two\n",
    "b = datetime.datetime.now().replace(microsecond = 0)\n",
    "print(b-a)\n",
    "\n",
    "#######========> End generation of new data points"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**This chunk of code below generates testing data and calculates the accuracy score for each state**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WY is finished...\n",
      "NM is finished...\n",
      "OK is finished...\n",
      "CO is finished...\n",
      "KS is finished...\n",
      "NE is finished...\n",
      "0:05:22\n"
     ]
    }
   ],
   "source": [
    "#######========> Implement code to train the KNN model, and calculate time elapsed\n",
    "\n",
    "#Define starting time\n",
    "a = datetime.datetime.now().replace(microsecond = 0)\n",
    "\n",
    "#Define set of states to be passed to train_algo function\n",
    "states = ['WY','NM','OK','CO','KS','NE']\n",
    "\n",
    "#Define number of test samples to be generated by test_sample function\n",
    "sample_num = 25\n",
    "\n",
    "#Define the number of trials for the training function to average over\n",
    "numtrials = 5\n",
    "\n",
    "#train_algo function returns the list of average accuracy scores\n",
    "accuracy = train_algo(states, numtrials, sample_num)\n",
    "\n",
    "#Define the ending time and print the difference\n",
    "b = datetime.datetime.now().replace(microsecond = 0)\n",
    "print(b-a)\n",
    "\n",
    "#######========> End code to train the KNN model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Below, the current accuracy scores by state fed into the training function are printed**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For state: WY, accuracy is: 0.94\n",
      "\n",
      "For state: NM, accuracy is: 0.98\n",
      "\n",
      "For state: OK, accuracy is: 0.95\n",
      "\n",
      "For state: CO, accuracy is: 0.98\n",
      "\n",
      "For state: KS, accuracy is: 0.93\n",
      "\n",
      "For state: NE, accuracy is: 0.94\n",
      "\n",
      "The mean accuracy score is: 0.95\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(states)):\n",
    "    print('For state: ' + str(states[i]) + ', accuracy is: ' + str(round(accuracy[i],2)) + '\\n')\n",
    "print('The mean accuracy score is: ' + str(round(np.mean(accuracy),2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save the current progress of new data point generation to the progress file\n",
    "combined.to_csv(path + 'Predicted_Counties_For_LatLong/GEOIDS_Progress.csv',\n",
    "                index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use the KNN Model to Predict Values and Write to File\n",
    "\n",
    "**Once I was satisfied with the predictive accuracy of the algorithm, I filled in the null GEOIDS with the KNN prediction, using the below code**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Latitude           0\n",
       "Longitude          0\n",
       "State              0\n",
       "State_Code         0\n",
       "County        603337\n",
       "GEOID              0\n",
       "LatLong            0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#######========> Implement code to fill the null GEOID values with the KNN predicted values\n",
    "\n",
    "#Define the X and Y columns passed into the KNN model\n",
    "xcols = ['Latitude','Longitude']\n",
    "ycols = ['GEOID']\n",
    "\n",
    "#Define the states to be passed into the KNN model\n",
    "states = ['WY','NM','OK','CO','KS','NE']\n",
    "\n",
    "#Define the KNN model with 1 neighbor\n",
    "model = KNeighborsClassifier(n_neighbors = 1)\n",
    "\n",
    "#Iterate over the desired states\n",
    "for state in states:\n",
    "    \n",
    "    #Define dataframes for the given state\n",
    "    df_train = combined[(combined.GEOID.notnull())&(combined.State == state)]\n",
    "    df_test = combined[(combined.GEOID.isnull())&(combined.State == state)]\n",
    "    \n",
    "    #Passing over the state if it doesn't have any null values to predict\n",
    "    if df_train[xcols].shape[0] > 0:\n",
    "        \n",
    "        #Define x_train, y_train, and the x values to be predicted\n",
    "        x_train = df_train[xcols]\n",
    "        y_train = df_train[ycols]\n",
    "        x_test  = df_test[xcols]\n",
    "        \n",
    "        #Fit the model to the training values\n",
    "        model.fit(x_train,y_train.values.ravel())\n",
    "        \n",
    "        #Write the model predictions over the GEOID null column values\n",
    "        combined.loc[(combined.GEOID.isnull())&\n",
    "                     (combined.State == state),'GEOID'] = model.predict(x_test)\n",
    "    \n",
    "    #If the state doesn't have any null values, just pass on move on to the next\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "#Add a new Lat/Long combo columns\n",
    "combined['LatLong'] = combined.Latitude + ',' + combined.Longitude\n",
    "    \n",
    "#Use this to ensure that all null values for GEOID were predicted with the KNN model\n",
    "combined.isnull().sum()\n",
    "\n",
    "#######========> End code to fill null GEOID values with KNN predicted GEOIDs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Merge the original wells dataframe with the newly filled in dataframe that has Lat/Longs and GEOIDS. Doing a left join so that only the Lat/Long combinations that are in the original file are filled in**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>State</th>\n",
       "      <th>Well_Name</th>\n",
       "      <th>Operator</th>\n",
       "      <th>Type</th>\n",
       "      <th>Status</th>\n",
       "      <th>Spud Date</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>API</th>\n",
       "      <th>LatLong</th>\n",
       "      <th>State_Code</th>\n",
       "      <th>GEOID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>WY</td>\n",
       "      <td>JOHN F JESSEN 1</td>\n",
       "      <td>Z &amp; S CONSTRUCTION CO INC</td>\n",
       "      <td>Oil Well</td>\n",
       "      <td>Producing Oil Well</td>\n",
       "      <td>19850727</td>\n",
       "      <td>-104.05490</td>\n",
       "      <td>41.30750</td>\n",
       "      <td>2120376</td>\n",
       "      <td>41.30750,-104.05490</td>\n",
       "      <td>56</td>\n",
       "      <td>56021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>WY</td>\n",
       "      <td>JESSEN 24-26</td>\n",
       "      <td>BEAR OIL AND GAS INC</td>\n",
       "      <td>Oil Well</td>\n",
       "      <td>Subsequent Report of Abandonment</td>\n",
       "      <td>20120917</td>\n",
       "      <td>-104.05519</td>\n",
       "      <td>41.31780</td>\n",
       "      <td>2120969</td>\n",
       "      <td>41.31780,-104.05519</td>\n",
       "      <td>56</td>\n",
       "      <td>56021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>WY</td>\n",
       "      <td>MALM 42-34</td>\n",
       "      <td>RANCH OIL COMPANY</td>\n",
       "      <td>Oil Well</td>\n",
       "      <td>Producing Oil Well</td>\n",
       "      <td>20100814</td>\n",
       "      <td>-104.05672</td>\n",
       "      <td>41.48507</td>\n",
       "      <td>2120659</td>\n",
       "      <td>41.48507,-104.05672</td>\n",
       "      <td>56</td>\n",
       "      <td>56021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>WY</td>\n",
       "      <td>AFTON GREEN 1</td>\n",
       "      <td>HARRISON SAM G</td>\n",
       "      <td>Oil Well</td>\n",
       "      <td>Subsequent Report of Abandonment</td>\n",
       "      <td>19641223</td>\n",
       "      <td>-104.05738</td>\n",
       "      <td>41.62074</td>\n",
       "      <td>1505009</td>\n",
       "      <td>41.62074,-104.05738</td>\n",
       "      <td>56</td>\n",
       "      <td>56015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>WY</td>\n",
       "      <td>CHARLES 5-10 1</td>\n",
       "      <td>DARRAH JOHN JAY JR</td>\n",
       "      <td>Oil Well</td>\n",
       "      <td>Subsequent Report of Abandonment</td>\n",
       "      <td>19961207</td>\n",
       "      <td>-104.06029</td>\n",
       "      <td>43.02864</td>\n",
       "      <td>2720972</td>\n",
       "      <td>43.02864,-104.06029</td>\n",
       "      <td>56</td>\n",
       "      <td>56027</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  State        Well_Name                   Operator      Type  \\\n",
       "0    WY  JOHN F JESSEN 1  Z & S CONSTRUCTION CO INC  Oil Well   \n",
       "1    WY     JESSEN 24-26       BEAR OIL AND GAS INC  Oil Well   \n",
       "2    WY       MALM 42-34          RANCH OIL COMPANY  Oil Well   \n",
       "3    WY    AFTON GREEN 1             HARRISON SAM G  Oil Well   \n",
       "4    WY   CHARLES 5-10 1         DARRAH JOHN JAY JR  Oil Well   \n",
       "\n",
       "                             Status Spud Date   Longitude  Latitude      API  \\\n",
       "0                Producing Oil Well  19850727  -104.05490  41.30750  2120376   \n",
       "1  Subsequent Report of Abandonment  20120917  -104.05519  41.31780  2120969   \n",
       "2                Producing Oil Well  20100814  -104.05672  41.48507  2120659   \n",
       "3  Subsequent Report of Abandonment  19641223  -104.05738  41.62074  1505009   \n",
       "4  Subsequent Report of Abandonment  19961207  -104.06029  43.02864  2720972   \n",
       "\n",
       "               LatLong State_Code  GEOID  \n",
       "0  41.30750,-104.05490         56  56021  \n",
       "1  41.31780,-104.05519         56  56021  \n",
       "2  41.48507,-104.05672         56  56021  \n",
       "3  41.62074,-104.05738         56  56015  \n",
       "4  43.02864,-104.06029         56  56027  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Merge the original wells frame with the newly filled combined frame\n",
    "with_id = pd.merge(wells_og, combined[['LatLong','GEOID']],\n",
    "                   how = 'left',\n",
    "                   on = 'LatLong')\n",
    "\n",
    "#Display the first five rows of the original wells dataset with the GEOIDS included\n",
    "with_id.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Lastly we will group the new dataframe by GEOID, aggregating by count so that the count of wells by county can be easily transferred to where the project data is held in excel**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GEOID\n",
       "08001    1737\n",
       "08003       1\n",
       "08005     339\n",
       "08007     215\n",
       "08009     309\n",
       "Name: GEOID, dtype: int64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Group by the GEOIDs and aggregate with a count\n",
    "predicted = with_id.groupby('GEOID')['GEOID'].count()\n",
    "\n",
    "#Save these final counts to a csv to be merged where the project was originally held in excel\n",
    "predicted.to_csv(path + 'Predicted_Counties_For_LatLong/KNN_predicted.csv',\n",
    "                 header = True)\n",
    "\n",
    "#Display the first 5 rows of the predicted groupby aggregation\n",
    "predicted.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
